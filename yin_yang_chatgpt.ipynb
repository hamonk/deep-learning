{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90b5a7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[addmm] Got 0 dimension input. Inputs must have at least one dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# 3. Initialize model and optimizer\u001b[39;00m\n\u001b[32m     37\u001b[39m model = MyModel()\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m optimizer = \u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# 4. Define binary cross entropy loss (logits)\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloss_fn\u001b[39m(model, X, y):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mlx-examples/mnist/.venv/lib/python3.12/site-packages/mlx/optimizers/optimizers.py:502\u001b[39m, in \u001b[36mAdam.__init__\u001b[39m\u001b[34m(self, learning_rate, betas, eps, bias_correction)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    494\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    495\u001b[39m     learning_rate: Union[\u001b[38;5;28mfloat\u001b[39m, Callable[[mx.array], mx.array]],\n\u001b[32m   (...)\u001b[39m\u001b[32m    498\u001b[39m     bias_correction: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    499\u001b[39m ):\n\u001b[32m    500\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m502\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_schedule\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlearning_rate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    503\u001b[39m     \u001b[38;5;28mself\u001b[39m.betas = betas\n\u001b[32m    504\u001b[39m     \u001b[38;5;28mself\u001b[39m.eps = eps\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mlx-examples/mnist/.venv/lib/python3.12/site-packages/mlx/optimizers/optimizers.py:151\u001b[39m, in \u001b[36mOptimizer._maybe_schedule\u001b[39m\u001b[34m(self, name, param)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param, Callable):\n\u001b[32m    150\u001b[39m     \u001b[38;5;28mself\u001b[39m._schedulers[name] = param\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     parameter = \u001b[43mparam\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    153\u001b[39m     parameter = mx.array(param)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mMyModel.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mlx-examples/mnist/.venv/lib/python3.12/site-packages/mlx/nn/layers/containers.py:23\u001b[39m, in \u001b[36mSequential.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m         x = \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mlx-examples/mnist/.venv/lib/python3.12/site-packages/mlx/nn/layers/linear.py:68\u001b[39m, in \u001b[36mLinear.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: mx.array) -> mx.array:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mbias\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         x = \u001b[43mmx\u001b[49m\u001b[43m.\u001b[49m\u001b[43maddmm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     70\u001b[39m         x = x @ \u001b[38;5;28mself\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m\"\u001b[39m].T\n",
      "\u001b[31mValueError\u001b[39m: [addmm] Got 0 dimension input. Inputs must have at least one dimension."
     ]
    }
   ],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "hidden_size = 20\n",
    "learning_rate = 0.01\n",
    "batch_size = 500\n",
    "epochs = 20\n",
    "\n",
    "# 1. Define the model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)  # No sigmoid here\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# 2. Generate synthetic training data\n",
    "def generate_data(n_samples=10000):\n",
    "    np.random.seed(42)\n",
    "    X = np.random.randn(n_samples, 2).astype(np.float32)\n",
    "    y = ((X[:, 0] * X[:, 1]) > 0).astype(np.float32).reshape(-1, 1)  # class 1 if signs match\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = generate_data(8000)\n",
    "X_test, y_test = generate_data(2000)\n",
    "\n",
    "# 3. Initialize model and optimizer\n",
    "model = MyModel()\n",
    "optimizer = optim.Adam(model, learning_rate)\n",
    "\n",
    "# 4. Define binary cross entropy loss (logits)\n",
    "def loss_fn(model, X, y):\n",
    "    logits = model(X)\n",
    "    return mx.mean(\n",
    "        mx.maximum(logits, 0) - logits * y + mx.log1p(mx.exp(-mx.abs(logits)))\n",
    "    )\n",
    "\n",
    "# 5. Gradient & optimization\n",
    "loss_and_grad_fn = nn.value_and_grad(model, loss_fn)\n",
    "\n",
    "@partial(mx.compile, inputs=model.state, outputs=model.state)\n",
    "def step(X, y):\n",
    "    loss, grads = loss_and_grad_fn(model, X, y)\n",
    "    optimizer.update(model, grads)\n",
    "    return loss\n",
    "\n",
    "@partial(mx.compile, inputs=model.state)\n",
    "def eval_fn(X, y):\n",
    "    preds = mx.sigmoid(model(X)) > 0.5\n",
    "    return mx.mean(preds == y)\n",
    "\n",
    "def batch_iterate(batch_size, X, y):\n",
    "    perm = np.random.permutation(len(X))\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        idx = perm[i : i + batch_size]\n",
    "        yield mx.array(X[idx]), mx.array(y[idx])\n",
    "\n",
    "# 6. Training loop\n",
    "tic = time.perf_counter()\n",
    "for e in range(epochs):\n",
    "    for Xb, yb in batch_iterate(batch_size, X_train, y_train):\n",
    "        step(Xb, yb)\n",
    "        mx.eval(model.state)\n",
    "\n",
    "    acc = eval_fn(mx.array(X_test), mx.array(y_test)).item()\n",
    "    loss = loss_fn(model, mx.array(X_test), mx.array(y_test)).item()\n",
    "    print(f\"Epoch {e+1:02d}: Accuracy = {acc:.3f}, Loss = {loss:.4f}, Time = {time.perf_counter() - tic:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77162d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'net': {'layers': [{'weight': array([[-0.301643, -0.09589],\n",
       "           [-0.679963, -0.502911],\n",
       "           [-0.596912, 0.162901],\n",
       "           ...,\n",
       "           [-0.208396, -0.292126],\n",
       "           [0.0380046, 0.585519],\n",
       "           [0.124601, 0.663408]], dtype=float32),\n",
       "    'bias': array([-0.466846, 0.0375038, 0.493884, ..., -0.423702, -0.0151615, 0.435534], dtype=float32)},\n",
       "   {},\n",
       "   {'weight': array([[-0.0809622, -0.208339, 0.141565, ..., 0.0374379, -0.221195, -0.151838]], dtype=float32),\n",
       "    'bias': array([0.107936], dtype=float32)}]}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
